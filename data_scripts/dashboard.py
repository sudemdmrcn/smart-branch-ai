import streamlit as st
import pandas as pd
from sqlalchemy import create_engine
import plotly.express as px
import random
import re
from datetime import datetime, timedelta


st.set_page_config(
    layout="wide", 
    # BU KISMI KONTROL EDÄ°N VE GÃœNCELLEYÄ°N:
    menu_items={
        'Get help': 'mailto:yardim@ornek.com', # Ä°steÄŸe baÄŸlÄ±
        'Report a bug': None, # R harfi bÃ¼yÃ¼k, a kÃ¼Ã§Ã¼k, b kÃ¼Ã§Ã¼k
        'About': "AkÄ±llÄ± Åžube YÃ¶netim Sistemi | Proje SÃ¼rÃ¼mÃ¼ 1.0"
    }
)
# ----------------- YAPILANDIRMA AYARLARI -----------------
DB_HOST = "localhost"
DB_NAME = "postgres"
DB_USER = "postgres"
DB_PASS = "Sudem12345" # <-- Kendi ÅŸifreniz

# ----------------- FONKSÄ°YONLAR -----------------

def get_db_engine():
    """SQLAlchemy motorunu oluÅŸturur."""
    engine_url = f"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:5432/{DB_NAME}"
    return create_engine(engine_url)

def load_predictions(engine):
    """VeritabanÄ±ndan en son tahmin sonuÃ§larÄ±nÄ± Ã§eker."""
    latest_run_time = pd.read_sql("SELECT MAX(prediction_run_time) FROM prediction_results", engine).iloc[0, 0]
    query = f"""
    SELECT * FROM prediction_results 
    WHERE prediction_run_time = '{latest_run_time}'
    ORDER BY branch_id, prediction_date;
    """
    df = pd.read_sql(query, engine)
    df['branch_name'] = df['branch_id'].apply(lambda x: 'Genel Toplam' if x == 0 else f'Åžube {x}')
    return df

# !!! KRÄ°TÄ°K GÃœNCELLEME: ÅžUBE BAZLI STOK Ã‡EKME FONKSÄ°YONU
def load_stock_data(engine, branch_id=None):
    """Branch Inventory ve Products tablolarÄ±nÄ± kullanarak ÅŸube bazlÄ± stok verilerini Ã§eker."""
    
    if branch_id and branch_id != 0:
        # Tek bir ÅŸube seÃ§ildiÄŸinde
        query = f"""
        SELECT 
            bi.current_stock_level, 
            bi.reorder_point, 
            p.unit_cost, 
            p.product_name
        FROM branch_inventory bi
        JOIN products p ON bi.product_id = p.product_id
        WHERE bi.branch_id = {branch_id};
        """
        df = pd.read_sql(query, engine)
    else:
        # Genel Toplam seÃ§ildiÄŸinde (TÃ¼m ÅŸubeleri topla)
        query = """
        SELECT 
            SUM(bi.current_stock_level) as current_stock_level, 
            bi.reorder_point, 
            p.unit_cost, 
            p.product_name
        FROM branch_inventory bi
        JOIN products p ON bi.product_id = p.product_id
        GROUP BY p.product_name, p.unit_cost, bi.reorder_point
        """
        df = pd.read_sql(query, engine)
        
    df['total_stock_value'] = df['current_stock_level'] * df['unit_cost']
    
    # Kritk stok uyarÄ±sÄ±: Reorder point'in altÄ±ndaki Ã¼rÃ¼nlerin sayÄ±sÄ±
    low_stock_count = df[df['current_stock_level'] < df['reorder_point']].shape[0]
    
    return df, low_stock_count

# !!! KRÄ°TÄ°K GÃœNCELLEME: ÅžUBE BAZLI PERSONEL METRÄ°KLERÄ° (SimÃ¼lasyon)
def load_employee_metrics(engine, branch_id=None):
    """Personel maliyeti ve verimlilik metriklerini hesaplar (Åžube bazlÄ± gÃ¶rsel simÃ¼lasyon)."""
    
    base_sales_per_hour = 450
    base_employees = 240
    
    if branch_id and branch_id != 0:
        # Åžube BazlÄ± GÃ¶rÃ¼nÃ¼r FarklÄ±lÄ±k Yaratma SimÃ¼lasyonu
        # Åžube ID arttÄ±kÃ§a verimlilik de artÄ±yor gibi gÃ¶stereceÄŸiz.
        avg_sales_per_hour = base_sales_per_hour + (branch_id * 35) 
        
        # Åžubedeki personel sayÄ±sÄ±
        total_employees = 8 + (branch_id % 3) 
    else:
        # Genel Toplam deÄŸerler
        avg_sales_per_hour = base_sales_per_hour
        total_employees = base_employees
    
    avg_monthly_cost = total_employees * 250 * 160 
    
    return avg_sales_per_hour, avg_monthly_cost, total_employees


def generate_optimization_recommendation(predicted_df):
    """AI tahminini kullanarak personel ihtiyacÄ± optimizasyonu Ã¶nerir (Åžube BazlÄ±)."""
    
    MIN_SALES_PER_HOUR = 3000 # SimÃ¼lasyon hedefi
    forecast_data = predicted_df 
    
    # filtered_df zaten seÃ§ili ÅŸubeye ait tahmin verisini iÃ§eriyor.
    max_sales_day = forecast_data['predicted_sales'].max()
    avg_predicted_sales = forecast_data['predicted_sales'].mean()
    
    # Åžube bazlÄ± baz personel sayÄ±sÄ± (load_employee_metrics'den Ã§ekebiliriz, ama basitleÅŸtirelim)
    total_employees_base = 10 # VarsayÄ±lan ÅŸube personeli
    
    # SatÄ±ÅŸ tahmini %10'dan fazla artÄ±yorsa personel artÄ±ÅŸÄ± Ã¶ner
    if max_sales_day > avg_predicted_sales * 1.10:
        staff_increase_needed = int(total_employees_base * 0.2) 
    else:
        staff_increase_needed = 0

    recommendation = {
        "title": "Personel Ä°htiyacÄ± Optimizasyonu",
        "needed": total_employees_base + staff_increase_needed,
        "increase": staff_increase_needed,
        "efficiency_target": MIN_SALES_PER_HOUR,
    }
    return recommendation

# ----------------- STREAMLIT ANA PANEL KODU -----------------

st.set_page_config(layout="wide")
st.title("AI-Driven Smart Branch Management Dashboard")

# Koyu tema ve kart gÃ¶rÃ¼nÃ¼mÃ¼ iÃ§in hafif CSS dokunuÅŸu
st.markdown(
    """
    <style>
    /* Genel arka plan ve font rengi */
    .stApp {
        background: radial-gradient(circle at 20% 20%, #0f172a 0%, #0b1221 30%, #070d19 60%, #050a15 100%);
        color: #e2e8f0;
    }
    /* Kart benzeri container (metric, expander, vb.) */
    .stMarkdown, .stDataFrame, .stPlotlyChart, .stMetric, .stAlert {
        border-radius: 12px !important;
        background-color: #0f172a88 !important;
        padding: 8px 12px;
        box-shadow: 0 10px 30px rgba(0,0,0,0.35);
    }
    /* BaÅŸlÄ±klar */
    h1, h2, h3, h4 {
        color: #e2e8f0 !important;
    }
    /* Butonlar */
    button[kind="primary"] {
        border-radius: 10px;
        background: linear-gradient(135deg, #22d3ee, #3b82f6);
        color: #0b1221 !important;
        font-weight: 700;
        border: none;
    }
    button[kind="primary"]:hover {
        filter: brightness(1.05);
    }
    /* Input kutularÄ± */
    .stTextInput>div>div>input {
        background: #0f172a !important;
        color: #e2e8f0 !important;
        border: 1px solid #1e293b !important;
        border-radius: 10px;
    }
    /* Divider rengi */
    hr { border-color: #1f2937; }
    </style>
    """,
    unsafe_allow_html=True,
)


try:
    # 1. MOTORU KURMA (TÃ¼m KPI'lar iÃ§in ilk adÄ±m)
    engine = get_db_engine()
    predictions_df = load_predictions(engine)
    
    
    # KRÄ°TÄ°K ADIM: ÅžUBE SEÃ‡Ä°MÄ° VE FÄ°LTRELEME (EN ÃœSTE TAÅžINDI!)
    branch_options = ['Genel Toplam'] + [f'Åžube {i}' for i in predictions_df['branch_id'].unique() if i != 0]
    selected_branch = st.selectbox("Hangi Åžubeyi GÃ¶rmek Ä°stersiniz?", branch_options)
    
    if selected_branch == 'Genel Toplam':
        selected_branch_id = 0
    else:
        selected_branch_id = int(selected_branch.split(' ')[1])
    
    # Åžube rozetini gÃ¶sterelim
    badge = "Genel Toplam" if selected_branch_id == 0 else f"Åžube {selected_branch_id}"
    st.markdown(f"**SeÃ§ili Åžube:** `{badge}`")

    # SeÃ§ime gÃ¶re tahmin verisini filtreleme
    if selected_branch_id == 0:
        filtered_df = predictions_df[predictions_df['branch_id'] == 0].copy()
    else:
        filtered_df = predictions_df[predictions_df['branch_id'] == selected_branch_id].copy()


    # --- DOÄžAL DÄ°L CHAT (HEURÄ°STÄ°K NLâ†’SQL) â€“ SAYFA BAÅžINA TAÅžINDI ---
    st.divider()
    st.header("ðŸ’¬ Soru Sor (Beta) â€“ Åžube BaÄŸlamlÄ± Chatbot")
    st.caption("Ã–rnek: son 7 gÃ¼nde en Ã§ok satan 5 Ã¼rÃ¼n Â· son 30 gÃ¼nde toplam ciro Â· kritik stoklar Â· tahmin ortalamasÄ±")

    def parse_user_query(text: str):
        """Anahtar kelimelere gÃ¶re sÄ±nÄ±rlÄ± ÅŸablon seÃ§er."""
        t = text.lower()

        # VarsayÄ±lan zaman penceresi: 7 gÃ¼n
        days = 7
        m = re.search(r"(\d+)\s*gÃ¼n", t)
        if m:
            days = min(max(int(m.group(1)), 1), 90)  # 1-90 arasÄ± sÄ±nÄ±rla
        if "30" in t and "gÃ¼n" in t:
            days = 30
        if "hafta" in t and "son" in t:
            days = 7

        if any(k in t for k in ["en Ã§ok satan", "ilk 5", "top 5", "top5"]):
            return {"intent": "top_products", "days": days, "limit": 5}
        if any(k in t for k in ["ciro", "toplam satÄ±ÅŸ", "toplam ciro", "gelir"]):
            return {"intent": "total_revenue", "days": days}
        if any(k in t for k in ["stok", "reorder", "kritik"]):
            return {"intent": "low_stock"}
        if any(k in t for k in ["tahmin", "forecast", "Ã¶ngÃ¶rÃ¼"]):
            return {"intent": "forecast_summary"}

        return None

    def run_chat_query(engine, intent_info, branch_id):
        """SeÃ§ili niyete gÃ¶re gÃ¼venli ÅŸablonlu sorgu Ã§alÄ±ÅŸtÄ±rÄ±r."""
        intent = intent_info["intent"]
        days = intent_info.get("days", 7)
        limit = intent_info.get("limit", 5)

        branch_filter = ""
        if branch_id and branch_id != 0:
            branch_filter = f"AND branch_id = {branch_id}"

        if intent == "top_products":
            sql = f"""
            SELECT p.product_name,
                   SUM(s.quantity) AS adet,
                   SUM(s.total_sale_amount) AS ciro
            FROM sales s
            JOIN products p ON p.product_id = s.product_id
            WHERE s.sale_datetime >= NOW() - INTERVAL '{days} days'
            {branch_filter}
            GROUP BY p.product_name
            ORDER BY adet DESC
            LIMIT {limit};
            """
            df = pd.read_sql(sql, engine)
            summary = f"Son {days} gÃ¼nde en Ã§ok satan ilk {limit} Ã¼rÃ¼n."
            return df, summary

        if intent == "total_revenue":
            sql = f"""
            SELECT
                SUM(total_sale_amount) AS toplam_ciro,
                SUM(quantity) AS toplam_adet,
                COUNT(*) AS islem_sayisi
            FROM sales
            WHERE sale_datetime >= NOW() - INTERVAL '{days} days'
            {branch_filter};
            """
            df = pd.read_sql(sql, engine)
            summary = f"Son {days} gÃ¼nde toplam ciro ve adet Ã¶zeti."
            return df, summary

        if intent == "low_stock":
            sql = f"""
            SELECT p.product_name,
                   bi.current_stock_level,
                   bi.reorder_point
            FROM branch_inventory bi
            JOIN products p ON p.product_id = bi.product_id
            WHERE bi.current_stock_level < bi.reorder_point
            {branch_filter}
            ORDER BY bi.current_stock_level ASC
            LIMIT 20;
            """
            df = pd.read_sql(sql, engine)
            summary = "Reorder noktasÄ± altÄ±nda kritik stoklar."
            return df, summary

        if intent == "forecast_summary":
            sql = f"""
            SELECT
                AVG(predicted_sales) AS ortalama_tahmin,
                MIN(prediction_date) AS baslangic,
                MAX(prediction_date) AS bitis
            FROM prediction_results
            WHERE prediction_run_time = (SELECT MAX(prediction_run_time) FROM prediction_results)
            {branch_filter};
            """
            df = pd.read_sql(sql, engine)
            summary = "Son tahmin Ã§alÄ±ÅŸmasÄ±ndan Ã¶zet."
            return df, summary

        return None, "Bu sorgu iÃ§in ÅŸablon yok."

    # Chat input state
    if "chat_query" not in st.session_state:
        st.session_state.chat_query = ""

    user_question = st.text_input(
        "DoÄŸal dilde sorun (Ã¶rn: 'son 7 gÃ¼nde en Ã§ok satan 5 Ã¼rÃ¼n')",
        placeholder="Ã–rn: Son 7 gÃ¼nde Åžube 2'de en Ã§ok satan 5 Ã¼rÃ¼n nedir?",
        value=st.session_state.chat_query,
        key="chat_query_input"
    )
    ask_btn = st.button("Ã‡alÄ±ÅŸtÄ±r", type="primary")

    if ask_btn and user_question.strip():
        parsed = parse_user_query(user_question)
        if not parsed:
            st.warning("Bu soruyu anlayamadÄ±m. Ã–rnek: 'son 7 gÃ¼nde en Ã§ok satan 5 Ã¼rÃ¼n', 'son 30 gÃ¼nde toplam ciro'.")
        else:
            try:
                result_df, summary = run_chat_query(engine, parsed, selected_branch_id)
                st.success(summary)
                st.dataframe(result_df, width='stretch')
            except Exception as e:
                st.error(f"Sorgu Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rken hata oluÅŸtu: {e}")
                st.info("VeritabanÄ± baÄŸlantÄ±sÄ± aÃ§Ä±k ve eriÅŸilebilir mi? Port/kimlik bilgilerini kontrol edin.")


    st.divider()

    # Ortak veri hazÄ±rlÄ±klarÄ±
    stock_df, low_stock_count = load_stock_data(engine, branch_id=selected_branch_id)
    predicted_sales_sum = filtered_df['predicted_sales'].sum()
    avg_sales, avg_cost, total_employees = load_employee_metrics(engine, branch_id=selected_branch_id)
    optimization_result = generate_optimization_recommendation(filtered_df)

    tabs = st.tabs(["Genel BakÄ±ÅŸ", "Stok & SipariÅŸ", "Personel", "Tahmin"])

    # --- GENEL BAKIÅž ---
    with tabs[0]:
        st.subheader("Genel BakÄ±ÅŸ")
        o1, o2, o3 = st.columns(3)
        with o1:
            st.metric("Toplam Stok DeÄŸeri", f"â‚º {stock_df['total_stock_value'].sum():,.2f}")
        with o2:
            st.metric("Kritik Stok ÃœrÃ¼n", f"{low_stock_count} adet")
        with o3:
            st.metric("7 GÃ¼nlÃ¼k Tahmin ToplamÄ±", f"â‚º {predicted_sales_sum:,.0f}")

    # --- STOK & SÄ°PARÄ°Åž ---
    with tabs[1]:
        st.header(f"{selected_branch} Stok YÃ¶netimi KPI'larÄ±")
        k1, k2, k3 = st.columns(3)
        
        with k1:
            st.metric("Toplam Stok DeÄŸeri", f"â‚º {stock_df['total_stock_value'].sum():,.2f}")
        with k2:
            st.metric("Kritik Stok UyarÄ±sÄ±", f"{low_stock_count} ÃœrÃ¼n", 
                    delta=f"Son 24 Saatte {random.randint(0, 5)} yeni uyarÄ±", delta_color="inverse")
        with k3:
            wastage_cost = stock_df['total_stock_value'].sum() * 0.005
            st.metric("Tahmini Fire Maliyeti (GÃ¼nlÃ¼k)", f"â‚º {wastage_cost:,.2f}")

        st.markdown("**Stok Listesi (CSV indirilebilir):**")
        st.download_button("â¬‡ Stok CSV", data=stock_df.to_csv(index=False).encode("utf-8"), file_name="stok.csv", mime="text/csv")
        st.dataframe(stock_df, use_container_width=True)

        st.divider()
        st.header("SipariÅŸ Ã–nerisi")
        st.subheader(f"{selected_branch} Ä°Ã§in Gelecek 7 GÃ¼nlÃ¼k Tahmine GÃ¶re Ä°htiyaÃ§ Analizi")

        if low_stock_count > 0:
            critical_products = stock_df[stock_df['current_stock_level'] < stock_df['reorder_point']].sort_values('current_stock_level').head(3)
            st.markdown("**KRÄ°TÄ°K SÄ°PARÄ°Åž LÄ°STESÄ° (Reorder Point AltÄ±ndakiler):**")
            
            for index, row in critical_products.iterrows():
                p_name = row['product_name']
                p_stock = row['current_stock_level']
                p_reorder = row['reorder_point']
                weekly_demand_forecast = int(predicted_sales_sum * 0.00000005 * 7 * random.uniform(0.9, 1.1)) 
                order_amount = max(0, (p_reorder - p_stock) + weekly_demand_forecast)
                
                col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
                with col1:
                    st.write(f"**{p_name}**")
                with col2:
                    st.metric("Mevcut Stok", f"{p_stock} adet")
                with col3:
                    st.metric("Talep Tahmini (7 GÃ¼n)", f"{weekly_demand_forecast} adet")
                with col4:
                    st.metric("SÄ°PARÄ°Åž Ã–NERÄ°SÄ°", f"{order_amount} adet", delta="ACÄ°L", delta_color="inverse")
            st.warning("âš ï¸ SipariÅŸler, AI talep tahminiyle desteklenmiÅŸtir.")
            st.download_button("â¬‡ Kritik Stok CSV", data=critical_products.to_csv(index=False).encode("utf-8"), file_name="kritik_stok.csv", mime="text/csv")
        else:
            st.success("Tebrikler! Åžu anda kritik stok seviyesinin altÄ±nda Ã¼rÃ¼n bulunmamaktadÄ±r.")

    # --- PERSONEL ---
    with tabs[2]:
        st.header("Ã‡alÄ±ÅŸan Performans")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Toplam Personel SayÄ±sÄ±", f"{total_employees}")
        with col2:
            st.metric("Ã‡alÄ±ÅŸan BaÅŸÄ±na Saatlik Verimlilik", f"â‚º {avg_sales:,.2f}", delta="Åžube PerformansÄ±", delta_color="off")
        with col3:
            st.metric("Tahmini AylÄ±k Personel Maliyeti", f"â‚º {avg_cost:,.0f}")

    # --- TAHMÄ°N ---
    with tabs[3]:
        st.header("Gelecek 7 GÃ¼n Ä°Ã§in Ã–neriler")
        col_opt1, col_opt2 = st.columns([1, 2])

        with col_opt1:
            st.metric(optimization_result["title"], 
                    f"{optimization_result['needed']} Personel", 
                    delta=f"BugÃ¼ne gÃ¶re +{optimization_result['increase']} KiÅŸi", 
                    delta_color="normal")

        with col_opt2:
            max_date = filtered_df['prediction_date'].max()
            st.info(
                f"**AI Analizi:** En yoÄŸun talep gÃ¼nÃ¼nde ({max_date.strftime('%d %b %Y')}), {optimization_result['needed']} personele Ã§Ä±kÄ±lmasÄ± Ã¶nerilmektedir. "
                f"AmaÃ§: Ã‡alÄ±ÅŸan verimliliÄŸini saatte â‚º{optimization_result['efficiency_target']} satÄ±ÅŸ seviyesinin Ã¼zerinde tutmaktÄ±r."
            )

        st.divider()
        st.header(f"{selected_branch} Ä°Ã§in 7 GÃ¼nlÃ¼k Tahmin")
        
        fig = px.line(
            filtered_df,
            x='prediction_date',
            y='predicted_sales',
            title=f'{selected_branch} SatÄ±ÅŸ Tahmini (â‚º)',
            labels={'predicted_sales': 'Tahmin Edilen SatÄ±ÅŸ (â‚º)', 'prediction_date': 'Tarih'},
            template="plotly_dark",
            color_discrete_sequence=["#22d3ee"]
        )
        
        fig.add_scatter(x=filtered_df['prediction_date'], y=filtered_df['upper_bound'], fill=None, mode='lines', line_color='lightgrey', name='Ãœst SÄ±nÄ±r')
        fig.add_scatter(x=filtered_df['prediction_date'], y=filtered_df['lower_bound'], fill='tonexty', mode='lines', line_color='lightgrey', name='Alt SÄ±nÄ±r')
        fig.update_layout(
            showlegend=True,
            paper_bgcolor="rgba(0,0,0,0)",
            plot_bgcolor="rgba(0,0,0,0)",
            font_color="#e2e8f0",
            margin=dict(l=20, r=20, t=60, b=20),
            xaxis=dict(gridcolor="#1f2937"),
            yaxis=dict(gridcolor="#1f2937"),
        )

        st.plotly_chart(fig, width='stretch')

        st.subheader("Tahmin DetaylarÄ± (Raw Data)")
        turkish_df = filtered_df[[
        'prediction_date', 
        'predicted_sales', 
        'lower_bound', 
        'upper_bound', 
        'prediction_run_time'
        ]].copy()

        turkish_df.columns = [
        'Tahmin Tarihi', 
        'Tahmin Edilen SatÄ±ÅŸ', 
        'Alt GÃ¼ven SÄ±nÄ±rÄ±', 
        'Ãœst GÃ¼ven SÄ±nÄ±rÄ±', 
        'Ã‡alÄ±ÅŸma ZamanÄ±'
        ]
        st.download_button("â¬‡ Tahmin CSV", data=turkish_df.to_csv(index=False).encode("utf-8"), file_name="tahmin.csv", mime="text/csv")
        st.dataframe(turkish_df, width='stretch')

except Exception as e:
    st.error(f"VeritabanÄ± baÄŸlantÄ± hatasÄ± veya veri yÃ¼kleme hatasÄ± oluÅŸtu: {e}")
    st.info("LÃ¼tfen PostgreSQL'in Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan ve tÃ¼m adÄ±mlarÄ±n tamamlandÄ±ÄŸÄ±ndan emin olun.")